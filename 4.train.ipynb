{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "22ff33e2",
   "metadata": {},
   "source": [
    "åŠ è½½ä¸¤ä¸ªå·¥å…·ç±»"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3af62b9",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mdiffusers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m DiffusionPipeline\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\n\u001b[0;32m      4\u001b[0m device \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcuda\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39mis_available() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcpu\u001b[39m\u001b[38;5;124m'\u001b[39m\n",
      "File \u001b[1;32md:\\Anaconda\\envs\\torch_env\\lib\\site-packages\\diffusers\\__init__.py:3\u001b[0m\n\u001b[0;32m      1\u001b[0m __version__ \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m0.12.1\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m----> 3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mconfiguration_utils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ConfigMixin\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m      5\u001b[0m     OptionalDependencyNotAvailable,\n\u001b[0;32m      6\u001b[0m     is_flax_available,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     17\u001b[0m     logging,\n\u001b[0;32m     18\u001b[0m )\n\u001b[0;32m     21\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[1;32md:\\Anaconda\\envs\\torch_env\\lib\\site-packages\\diffusers\\configuration_utils.py:34\u001b[0m\n\u001b[0;32m     31\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mrequests\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m HTTPError\n\u001b[0;32m     33\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m __version__\n\u001b[1;32m---> 34\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m DIFFUSERS_CACHE, HUGGINGFACE_CO_RESOLVE_ENDPOINT, DummyObject, deprecate, logging\n\u001b[0;32m     37\u001b[0m logger \u001b[38;5;241m=\u001b[39m logging\u001b[38;5;241m.\u001b[39mget_logger(\u001b[38;5;18m__name__\u001b[39m)\n\u001b[0;32m     39\u001b[0m _re_configuration_file \u001b[38;5;241m=\u001b[39m re\u001b[38;5;241m.\u001b[39mcompile(\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mconfig\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124m.(.*)\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124m.json\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32md:\\Anaconda\\envs\\torch_env\\lib\\site-packages\\diffusers\\utils\\__init__.py:68\u001b[0m\n\u001b[0;32m     66\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01moutputs\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m BaseOutput\n\u001b[0;32m     67\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpil_utils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m PIL_INTERPOLATION\n\u001b[1;32m---> 68\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtorch_utils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m randn_tensor\n\u001b[0;32m     71\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_torch_available():\n\u001b[0;32m     72\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtesting_utils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m     73\u001b[0m         floats_tensor,\n\u001b[0;32m     74\u001b[0m         load_hf_numpy,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     83\u001b[0m         torch_device,\n\u001b[0;32m     84\u001b[0m     )\n",
      "File \u001b[1;32md:\\Anaconda\\envs\\torch_env\\lib\\site-packages\\diffusers\\utils\\torch_utils.py:24\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mimport_utils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m is_torch_available\n\u001b[0;32m     23\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_torch_available():\n\u001b[1;32m---> 24\u001b[0m     \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\n\u001b[0;32m     26\u001b[0m logger \u001b[38;5;241m=\u001b[39m logging\u001b[38;5;241m.\u001b[39mget_logger(\u001b[38;5;18m__name__\u001b[39m)  \u001b[38;5;66;03m# pylint: disable=invalid-name\u001b[39;00m\n\u001b[0;32m     29\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mrandn_tensor\u001b[39m(\n\u001b[0;32m     30\u001b[0m     shape: Union[Tuple, List],\n\u001b[0;32m     31\u001b[0m     generator: Optional[Union[List[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtorch.Generator\u001b[39m\u001b[38;5;124m\"\u001b[39m], \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtorch.Generator\u001b[39m\u001b[38;5;124m\"\u001b[39m]] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     34\u001b[0m     layout: Optional[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtorch.layout\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m     35\u001b[0m ):\n",
      "File \u001b[1;32md:\\Anaconda\\envs\\torch_env\\lib\\site-packages\\torch\\__init__.py:1919\u001b[0m\n\u001b[0;32m   1917\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m library\n\u001b[0;32m   1918\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m TYPE_CHECKING:\n\u001b[1;32m-> 1919\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _meta_registrations\n\u001b[0;32m   1921\u001b[0m \u001b[38;5;66;03m# Enable CUDA Sanitizer\u001b[39;00m\n\u001b[0;32m   1922\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTORCH_CUDA_SANITIZER\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01min\u001b[39;00m os\u001b[38;5;241m.\u001b[39menviron:\n",
      "File \u001b[1;32md:\\Anaconda\\envs\\torch_env\\lib\\site-packages\\torch\\_meta_registrations.py:821\u001b[0m\n\u001b[0;32m    817\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcloneBatchedColumnMajor\u001b[39m(src: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m    818\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m src\u001b[38;5;241m.\u001b[39mmT\u001b[38;5;241m.\u001b[39mclone(memory_format\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mcontiguous_format)\u001b[38;5;241m.\u001b[39mtranspose(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m--> 821\u001b[0m \u001b[38;5;129m@register_meta\u001b[39m(\u001b[43maten\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_cholesky_solve_helper\u001b[49m)\n\u001b[0;32m    822\u001b[0m \u001b[38;5;129m@out_wrapper\u001b[39m()\n\u001b[0;32m    823\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_cholesky_solve_helper\u001b[39m(\u001b[38;5;28mself\u001b[39m: Tensor, A: Tensor, upper: \u001b[38;5;28mbool\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m    824\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m cloneBatchedColumnMajor(\u001b[38;5;28mself\u001b[39m)\n\u001b[0;32m    827\u001b[0m \u001b[38;5;129m@register_meta\u001b[39m(aten\u001b[38;5;241m.\u001b[39mcholesky_solve)\n\u001b[0;32m    828\u001b[0m \u001b[38;5;129m@out_wrapper\u001b[39m()\n\u001b[0;32m    829\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcholesky_solve\u001b[39m(\u001b[38;5;28mself\u001b[39m: Tensor, A: Tensor, upper: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n",
      "File \u001b[1;32md:\\Anaconda\\envs\\torch_env\\lib\\site-packages\\torch\\_ops.py:920\u001b[0m, in \u001b[0;36m_OpNamespace.__getattr__\u001b[1;34m(self, op_name)\u001b[0m\n\u001b[0;32m    918\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    919\u001b[0m     op, overload_names \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39m_C\u001b[38;5;241m.\u001b[39m_jit_get_operation(qualified_op_name)\n\u001b[1;32m--> 920\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[43mop\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m:\n\u001b[0;32m    921\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(\n\u001b[0;32m    922\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_OpNamespace\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m object has no attribute \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mop_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    923\u001b[0m         )\n\u001b[0;32m    924\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    925\u001b[0m     \u001b[38;5;66;03m# Turn this into AttributeError so getattr(obj, key, default)\u001b[39;00m\n\u001b[0;32m    926\u001b[0m     \u001b[38;5;66;03m# works (this is called by TorchScript with __origin__)\u001b[39;00m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# ä» ğŸ¤— Diffusers å¯¼å…¥ DiffusionPipelineï¼ˆæŠŠ UNetã€VAEã€æ–‡æœ¬ç¼–ç å™¨ã€è°ƒåº¦å™¨ç­‰ç»„ä»¶æ‰“åŒ…åˆ°ä¸€èµ·çš„ä¸€ç«™å¼æ¨ç†ç®¡é“ï¼‰ã€‚\n",
    "# å¯¼å…¥ PyTorchã€‚\n",
    "from diffusers import DiffusionPipeline\n",
    "import torch\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "# é€šè¿‡ from_pretrained ä»ç»™å®šä»“åº“/è·¯å¾„åŠ è½½ä¸€ä¸ªå·²ç»é…å¥½çš„æ‰©æ•£æ¨¡å‹ç®¡é“ï¼ˆæƒé‡å’Œé…ç½®ï¼‰ã€‚\n",
    "# safety_checker=None å…³é—­ NSFW å®‰å…¨è¿‡æ»¤å™¨ï¼ˆç”Ÿæˆå†…å®¹å°†ä¸åšé¢å¤–å®¡æŸ¥ï¼‰ã€‚\n",
    "# è¿™ä¸€æ­¥ä¼šæŠŠæ–‡æœ¬ç¼–ç å™¨ã€UNetã€VAEã€schedulerã€tokenizerç­‰å­æ¨¡å—éƒ½è£…åˆ° pipeline é‡Œï¼ˆé»˜è®¤åœ¨ CPU ä¸Šï¼‰ã€‚\n",
    "pipeline = DiffusionPipeline.from_pretrained(\n",
    "    'lansinuote/diffsion_from_scratch.params', safety_checker=None)\n",
    "\n",
    "scheduler = pipeline.scheduler # æ˜¯å¾€å›¾ç‰‡ä¸­å‚å…¥å™ªå£°çš„å·¥å…·ç±»\n",
    "tokenizer = pipeline.tokenizer\n",
    "\n",
    "del pipeline # åˆ é™¤å¤§è€Œå…¨çš„ pipeline å¯¹è±¡æœ¬èº«ä»¥é‡Šæ”¾å†…å­˜ï¼ˆæƒé‡å¤§ã€å  RAM/æ˜¾å­˜ï¼‰ã€‚\n",
    "             # å·²ç»å•ç‹¬æ‹¿å‡ºæ¥çš„ scheduler ä¸ tokenizer åªæ˜¯ç‹¬ç«‹å¼•ç”¨ï¼Œä¸ä¼šè¢«åˆ ã€‚\n",
    "\n",
    "# åœ¨ Jupyter/REPL ä¸­ï¼Œå•ç‹¬ä¸€è¡Œå†™å¤šä¸ªå˜é‡ä¼šå›æ˜¾ä¸€ä¸ªå…ƒç»„ (device, scheduler, tokenizer)ï¼Œä¾¿äºä½ çœ‹å½“å‰ä¸‰è€…çš„å€¼/ç±»å‹ã€‚\n",
    "# åœ¨æ™®é€š .py æ–‡ä»¶é‡Œï¼Œè¿™ä¸€è¡Œä¸ä¼šæ‰“å°ä»»ä½•ä¸œè¥¿ï¼ˆé™¤é print(...)ï¼‰ã€‚\n",
    "device, scheduler, tokenizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c04403f4",
   "metadata": {},
   "source": [
    "å¯¹æ•°æ®å½“ä¸­çš„å›¾ç‰‡å’Œæ–‡æœ¬åˆ†åˆ«è¿›è¡Œç¼–ç "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd207966",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration lansinuote--diffsion_from_scratch-34318fc75271f5a0\n",
      "Found cached dataset parquet (/root/.cache/huggingface/datasets/lansinuote___parquet/lansinuote--diffsion_from_scratch-34318fc75271f5a0/0.0.0/2a3b91fbd88a2c90d1dbbb32b460cf621d31bd5b05b934492fdef7d8d6f236ec)\n",
      "Loading cached processed dataset at /root/.cache/huggingface/datasets/lansinuote___parquet/lansinuote--diffsion_from_scratch-34318fc75271f5a0/0.0.0/2a3b91fbd88a2c90d1dbbb32b460cf621d31bd5b05b934492fdef7d8d6f236ec/cache-314ecfdae0cf40d9.arrow\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(Dataset({\n",
       "     features: ['pixel_values', 'input_ids'],\n",
       "     num_rows: 833\n",
       " }),\n",
       " {'pixel_values': tensor([[[1., 1., 1.,  ..., 1., 1., 1.],\n",
       "           [1., 1., 1.,  ..., 1., 1., 1.],\n",
       "           [1., 1., 1.,  ..., 1., 1., 1.],\n",
       "           ...,\n",
       "           [1., 1., 1.,  ..., 1., 1., 1.],\n",
       "           [1., 1., 1.,  ..., 1., 1., 1.],\n",
       "           [1., 1., 1.,  ..., 1., 1., 1.]],\n",
       "  \n",
       "          [[1., 1., 1.,  ..., 1., 1., 1.],\n",
       "           [1., 1., 1.,  ..., 1., 1., 1.],\n",
       "           [1., 1., 1.,  ..., 1., 1., 1.],\n",
       "           ...,\n",
       "           [1., 1., 1.,  ..., 1., 1., 1.],\n",
       "           [1., 1., 1.,  ..., 1., 1., 1.],\n",
       "           [1., 1., 1.,  ..., 1., 1., 1.]],\n",
       "  \n",
       "          [[1., 1., 1.,  ..., 1., 1., 1.],\n",
       "           [1., 1., 1.,  ..., 1., 1., 1.],\n",
       "           [1., 1., 1.,  ..., 1., 1., 1.],\n",
       "           ...,\n",
       "           [1., 1., 1.,  ..., 1., 1., 1.],\n",
       "           [1., 1., 1.,  ..., 1., 1., 1.],\n",
       "           [1., 1., 1.,  ..., 1., 1., 1.]]]),\n",
       "  'input_ids': tensor([49406,   320,  3610,   539,   320,  1901,  9528,   593,   736,  3095,\n",
       "          49407, 49407, 49407, 49407, 49407, 49407, 49407, 49407, 49407, 49407,\n",
       "          49407, 49407, 49407, 49407, 49407, 49407, 49407, 49407, 49407, 49407,\n",
       "          49407, 49407, 49407, 49407, 49407, 49407, 49407, 49407, 49407, 49407,\n",
       "          49407, 49407, 49407, 49407, 49407, 49407, 49407, 49407, 49407, 49407,\n",
       "          49407, 49407, 49407, 49407, 49407, 49407, 49407, 49407, 49407, 49407,\n",
       "          49407, 49407, 49407, 49407, 49407, 49407, 49407, 49407, 49407, 49407,\n",
       "          49407, 49407, 49407, 49407, 49407, 49407, 49407])})"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "import torchvision\n",
    "\n",
    "#åŠ è½½æ•°æ®é›†\n",
    "dataset = load_dataset(path='lansinuote/diffsion_from_scratch', split='train')\n",
    "\n",
    "#å›¾åƒå¢å¼ºæ¨¡å—\n",
    "compose = torchvision.transforms.Compose([\n",
    "    torchvision.transforms.Resize(\n",
    "        512, interpolation=torchvision.transforms.InterpolationMode.BILINEAR),\n",
    "    torchvision.transforms.CenterCrop(512),\n",
    "    #torchvision.transforms.RandomHorizontalFlip(),\n",
    "    torchvision.transforms.ToTensor(),\n",
    "    torchvision.transforms.Normalize([0.5], [0.5]),\n",
    "])\n",
    "\n",
    "\n",
    "def f(data):\n",
    "    #åº”ç”¨å›¾åƒå¢å¼º\n",
    "    pixel_values = [compose(i) for i in data['image']]\n",
    "    # map(..., batched=True) æ—¶ï¼Œdata['image'] æ˜¯ä¸€ä¸ªæ‰¹æ¬¡çš„åˆ—è¡¨ï¼ˆé•¿åº¦â‰¤batch_sizeï¼‰ï¼Œå¯¹æ¯å¼ å›¾åš composeï¼Œå¾—åˆ°ä¸€å † [C,512,512] çš„å¼ é‡ã€‚\n",
    "\n",
    "    #æ–‡å­—ç¼–ç \n",
    "    input_ids = tokenizer.batch_encode_plus(data['text'],\n",
    "                                            padding='max_length',\n",
    "                                            truncation=True,\n",
    "                                            max_length=77).input_ids # æ‰¹é‡æŠŠæ–‡æœ¬è½¬æˆ token idï¼š\n",
    "                                                # å›ºå®š é•¿åº¦ 77ï¼ˆCLIP å¸¸ç”¨é•¿åº¦ï¼‰ï¼Œä¸è¶³åˆ™ç”¨ pad è¡¥åˆ° 77ï¼Œè¿‡é•¿åˆ™æˆªæ–­ï¼›\n",
    "                                                # input_ids æ˜¯ List[List[int]]ï¼Œæ¯æ¡æ ·æœ¬ 77 ä¸ª idï¼ˆæœ«å°¾å¾ˆå¤šæ˜¯ pad idï¼‰ã€‚\n",
    "\n",
    "    return {'pixel_values': pixel_values, 'input_ids': input_ids}\n",
    "    # è¿”å›ç»™ datasetsï¼Œæ–°åˆ—å« pixel_values å’Œ input_idsã€‚datasets ä¼šæ®æ­¤æ¨æ–­ç‰¹å¾ç±»å‹ä¸å½¢çŠ¶ã€‚\n",
    "\n",
    "\"\"\"\n",
    "batched=Trueï¼šf ä¸€æ¬¡å¤„ç†ä¸€ä¸ªæ‰¹æ¬¡ï¼Œæ›´é«˜æ•ˆï¼›\n",
    "batch_size=100ï¼šæ¯æ‰¹ 100 æ¡æ•°æ®ä¼ ç»™ fï¼›\n",
    "num_proc=1ï¼šå•è¿›ç¨‹æ˜ å°„ï¼ˆè®¾æˆ>1 å¯å¤šè¿›ç¨‹å¹¶è¡Œï¼‰ï¼›\n",
    "remove_columns=['image','text']ï¼šä¸¢æ‰åŸå§‹çš„ image/text ä¸¤åˆ—ï¼Œé¿å…é‡å¤å­˜å‚¨ï¼Œæœ€ååªä¿ç•™å¤„ç†åçš„ä¸¤åˆ—ã€‚\n",
    "\"\"\"\n",
    "dataset = dataset.map(f,\n",
    "                      batched=True,\n",
    "                      batch_size=100,\n",
    "                      num_proc=1,\n",
    "                      remove_columns=['image', 'text'])\n",
    "\n",
    "\"\"\"\n",
    "æŒ‡å®šå–æ ·æœ¬/æ‰¹æ¬¡æ—¶ï¼ŒæŠŠè¿™äº›åˆ—è‡ªåŠ¨è½¬æˆ PyTorch å¼ é‡ï¼š\n",
    "pixel_valuesï¼štorch.float32ï¼Œå½¢çŠ¶ [C,512,512]ï¼›\n",
    "input_idsï¼štorch.int64ï¼Œå½¢çŠ¶ [77]ã€‚\n",
    "\"\"\"\n",
    "dataset.set_format(type='torch')\n",
    "\n",
    "\"\"\"\n",
    "åœ¨ Notebook é‡Œï¼Œè¿™ä¸€è¡Œä¼šå›æ˜¾ä¸¤ä¸ªå€¼ï¼š\n",
    "dataset çš„æ¦‚å†µï¼ˆfeaturesã€num_rows ç­‰ï¼‰ï¼›\n",
    "ç¬¬ä¸€æ¡æ ·æœ¬çš„å­—å…¸ï¼š{'pixel_values': tensor(...), 'input_ids': tensor([...])}ã€‚\n",
    "\"\"\"\n",
    "dataset, dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69854652",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(833,\n",
       " {'pixel_values': tensor([[[[1., 1., 1.,  ..., 1., 1., 1.],\n",
       "            [1., 1., 1.,  ..., 1., 1., 1.],\n",
       "            [1., 1., 1.,  ..., 1., 1., 1.],\n",
       "            ...,\n",
       "            [1., 1., 1.,  ..., 1., 1., 1.],\n",
       "            [1., 1., 1.,  ..., 1., 1., 1.],\n",
       "            [1., 1., 1.,  ..., 1., 1., 1.]],\n",
       "  \n",
       "           [[1., 1., 1.,  ..., 1., 1., 1.],\n",
       "            [1., 1., 1.,  ..., 1., 1., 1.],\n",
       "            [1., 1., 1.,  ..., 1., 1., 1.],\n",
       "            ...,\n",
       "            [1., 1., 1.,  ..., 1., 1., 1.],\n",
       "            [1., 1., 1.,  ..., 1., 1., 1.],\n",
       "            [1., 1., 1.,  ..., 1., 1., 1.]],\n",
       "  \n",
       "           [[1., 1., 1.,  ..., 1., 1., 1.],\n",
       "            [1., 1., 1.,  ..., 1., 1., 1.],\n",
       "            [1., 1., 1.,  ..., 1., 1., 1.],\n",
       "            ...,\n",
       "            [1., 1., 1.,  ..., 1., 1., 1.],\n",
       "            [1., 1., 1.,  ..., 1., 1., 1.],\n",
       "            [1., 1., 1.,  ..., 1., 1., 1.]]]], device='cuda:0'),\n",
       "  'input_ids': tensor([[49406,   320,  3610,   539,   320,  7651,  4009,   530,  3360,   537,\n",
       "            5046, 49407, 49407, 49407, 49407, 49407, 49407, 49407, 49407, 49407,\n",
       "           49407, 49407, 49407, 49407, 49407, 49407, 49407, 49407, 49407, 49407,\n",
       "           49407, 49407, 49407, 49407, 49407, 49407, 49407, 49407, 49407, 49407,\n",
       "           49407, 49407, 49407, 49407, 49407, 49407, 49407, 49407, 49407, 49407,\n",
       "           49407, 49407, 49407, 49407, 49407, 49407, 49407, 49407, 49407, 49407,\n",
       "           49407, 49407, 49407, 49407, 49407, 49407, 49407, 49407, 49407, 49407,\n",
       "           49407, 49407, 49407, 49407, 49407, 49407, 49407]], device='cuda:0')})"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#å®šä¹‰loader\n",
    "def collate_fn(data): # è‡ªå®šä¹‰ æ‰“åŒ…å‡½æ•°ã€‚DataLoader æ¯æ¬¡å–ä¸€ä¸ª batch æ—¶ï¼Œä¼šæŠŠè¯¥ batch å†…çš„æ ·æœ¬åˆ—è¡¨ä¼ è¿›æ¥ï¼ˆdata æ˜¯ä¸€ä¸ª listï¼Œé•¿åº¦=batch_sizeï¼›å…ƒç´ æ˜¯ä½  dataset[?] è¿”å›çš„ dictï¼‰ã€‚\n",
    "    \"\"\"\n",
    "    ä»è¿™æ‰¹æ ·æœ¬é‡Œåˆ†åˆ«å–å‡ºå›¾åƒä¸æ–‡æœ¬ä¸¤åˆ—ï¼Œå½¢æˆä¸¤ä¸ª listï¼š\n",
    "    pixel_valuesï¼šé•¿åº¦ = batch_sizeï¼Œæ¯ä¸ªå…ƒç´ å½¢çŠ¶æ˜¯ [C, 512, 512] çš„å¼ é‡ï¼ˆfloat32ï¼ŒèŒƒå›´[-1,1]ï¼‰ã€‚\n",
    "    input_idsï¼šé•¿åº¦ = batch_sizeï¼Œæ¯ä¸ªå…ƒç´ å½¢çŠ¶æ˜¯ [77] çš„å¼ é‡ï¼ˆint64ï¼‰ã€‚\n",
    "    \"\"\"\n",
    "    pixel_values = [i['pixel_values'] for i in data]\n",
    "    input_ids = [i['input_ids'] for i in data]\n",
    "\n",
    "    \"\"\"\n",
    "    torch.stack åœ¨æ–°ç»´åº¦ä¸Šæ‹¼æ¥ï¼Œå¾—åˆ°æ‰¹é‡å¼ é‡ï¼š\n",
    "    pixel_values å˜ä¸º [B, C, 512, 512]\n",
    "    input_ids å˜ä¸º [B, 77]\n",
    "    .to(device) æŠŠè¿™ä¸¤ä¸ªå¼ é‡ç›´æ¥æ¬åˆ°è®¾å¤‡ï¼ˆ'cuda' æˆ– 'cpu'ï¼‰ã€‚\n",
    "    è¿™æ ·åšçš„å¥½å¤„ï¼šæ¯ä¸ª batch äº§å‡ºå³åœ¨ç›®æ ‡è®¾å¤‡ï¼Œåé¢è®­ç»ƒ/æ¨ç†æ—¶æ— éœ€å†æ¬è¿ã€‚\n",
    "    \"\"\"\n",
    "    pixel_values = torch.stack(pixel_values).to(device)\n",
    "    input_ids = torch.stack(input_ids).to(device)\n",
    "\n",
    "    # è¿”å›ä¸€ä¸ªæ‰¹çš„å­—å…¸ï¼›åç»­æ¨¡å‹å‰å‘å¯ç›´æ¥è§£åŒ…ä½¿ç”¨ã€‚\n",
    "    return {'pixel_values': pixel_values, 'input_ids': input_ids}\n",
    "\n",
    "\n",
    "loader = torch.utils.data.DataLoader(dataset,\n",
    "                                     shuffle=True,\n",
    "                                     collate_fn=collate_fn,\n",
    "                                     batch_size=1)\n",
    "\n",
    "len(loader), next(iter(loader)) # len(loader)ï¼šbatch çš„æ•°é‡ã€‚ä½ çš„æ•°æ®é›†å¤§å°ä¹‹å‰æ˜¾ç¤ºä¸º 833ï¼Œbatch_size=1ï¼Œå› æ­¤ len(loader) = 833ã€‚\n",
    "# next(iter(loader))ï¼šå–ç¬¬ä¸€ä¸ª batchï¼ˆå› ä¸º shuffle=Trueï¼Œå®ƒæ˜¯éšæœºçš„ä¸€æ¡ï¼‰ã€‚è¿”å›å­—å…¸ï¼š\n",
    "# batch['pixel_values']ï¼šå½¢çŠ¶ [1, C, 512, 512]ï¼Œdtype=torch.float32ï¼Œä½äº device\n",
    "# batch['input_ids']ï¼šå½¢çŠ¶ [1, 77]ï¼Œdtype=torch.int64ï¼Œä½äº device\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53704bed",
   "metadata": {},
   "source": [
    "åŠ è½½æ¨¡å‹ å‡†å¤‡è®­ç»ƒ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "217c0a9c",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The config attributes {'scaling_factor': 0.18215} were passed to AutoencoderKL, but are not expected and will be ignored. Please verify your config.json configuration file.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(AdamW (\n",
       " Parameter Group 0\n",
       "     amsgrad: False\n",
       "     betas: (0.9, 0.999)\n",
       "     capturable: False\n",
       "     eps: 1e-08\n",
       "     foreach: None\n",
       "     lr: 1e-05\n",
       "     maximize: False\n",
       "     weight_decay: 0.01\n",
       " ),\n",
       " MSELoss())"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#åŠ è½½æ¨¡å‹\n",
    "%run 1.encoder.ipynb\n",
    "%run 2.vae.ipynb\n",
    "%run 3.unet.ipynb\n",
    "\n",
    "#å‡†å¤‡è®­ç»ƒ\n",
    "encoder.requires_grad_(False)\n",
    "vae.requires_grad_(False)\n",
    "unet.requires_grad_(True)\n",
    "\n",
    "encoder.eval()\n",
    "vae.eval()\n",
    "unet.train()\n",
    "\n",
    "encoder.to(device)\n",
    "vae.to(device)\n",
    "unet.to(device)\n",
    "\n",
    "optimizer = torch.optim.AdamW(unet.parameters(),\n",
    "                              lr=1e-5,\n",
    "                              betas=(0.9, 0.999),\n",
    "                              weight_decay=0.01,\n",
    "                              eps=1e-8)\n",
    "\n",
    "criterion = torch.nn.MSELoss()\n",
    "\n",
    "optimizer, criterion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "355b7e2e",
   "metadata": {},
   "source": [
    "è®¡ç®— Loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03d4a806",
   "metadata": {},
   "source": [
    "å…¸å‹çš„æ‰©æ•£æ¨¡å‹ï¼ˆStable Diffusion é£æ ¼ï¼‰è®­ç»ƒä¸€æ­¥ï¼šå›ºå®šæ–‡æœ¬ç¼–ç å™¨ä¸VAEï¼Œåªè®­ç»ƒUNetï¼Œè®©å®ƒåœ¨ç»™å®štæ­¥çš„å™ªå£°æ°´å¹³ä¸‹é¢„æµ‹å™ªå£° Îµï¼Œç”¨MSEå¯¹é½çœŸå™ªå£°ã€‚\n",
    "\n",
    "è¿™æ®µä»£ç åšäº†ï¼šå†»ç»“æ–‡æœ¬ä¸VAE â†’ å¾—åˆ°æ¡ä»¶æ–‡æœ¬åµŒå…¥ä¸æ½œç©ºé—´latent â†’ éšæœºé€‰tæŠŠå™ªå£°åŠ åˆ°latentä¸Šå½¢æˆx_t â†’ ç”¨UNetåœ¨(t, æ–‡æœ¬æ¡ä»¶)ä¸‹é¢„æµ‹å™ªå£°Îµ â†’ ç”¨MSEæŠŠé¢„æµ‹å’ŒçœŸå™ªå£°å¯¹é½ã€‚è®­ç»ƒå……åˆ†åï¼Œæ¨ç†æ—¶å°±èƒ½ä»çº¯å™ªå£°ä¸€æ­¥æ­¥å»å™ªç”Ÿæˆæ½œå‘é‡ï¼Œå†ç»VAEè§£ç å›å›¾åƒã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3f32e9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "å®šä¹‰ä¸€ä¸ªå‡½æ•°åšä¸€æ¬¡å‰å‘+è®¡ç®—lossã€‚data æ˜¯ä¸€ä¸ªå­—å…¸ï¼Œè‡³å°‘åŒ…å«ï¼š\n",
    "data['input_ids']: æ–‡æœ¬token idsï¼Œå½¢çŠ¶ [B, 77]ï¼ˆè¿™é‡Œç¤ºä¾‹B=1ï¼‰\n",
    "data['pixel_values']: åŸå›¾åƒå¼ é‡ï¼Œå½¢çŠ¶ [B, 3, 512, 512]\n",
    "\"\"\"\n",
    "def get_loss(data):\n",
    "    with torch.no_grad(): # åœ¨è¿™ä¸ªå—é‡Œå…³é—­æ¢¯åº¦ã€‚ç›®çš„ï¼š\n",
    "                            # æ–‡æœ¬ç¼–ç å™¨ encoder å’Œ VAE ç¼–ç å™¨é€šå¸¸ä¸è®­ç»ƒï¼ˆå†»ç»“ï¼‰ï¼Œ\n",
    "                            # èŠ‚çœæ˜¾å­˜å’ŒåŠ é€Ÿå‰å‘ã€‚\n",
    "        #æ–‡å­—ç¼–ç \n",
    "        #[1, 77] -> [1, 77, 768]\n",
    "        out_encoder = encoder(data['input_ids'])\n",
    "\n",
    "        \"\"\"\n",
    "        é€šè¿‡VAEæŠŠåƒç´ ç©ºé—´æ˜ å°„åˆ°æ½œç©ºé—´ï¼ˆlatentï¼‰ï¼š\n",
    "        vae.encoder(...) é€šå¸¸è¾“å‡ºé«˜æ–¯åˆ†å¸ƒçš„å‚æ•°ï¼ˆå¦‚å‡å€¼Î¼ã€logvarï¼‰ï¼Œå½¢çŠ¶å†…éƒ¨ç»“æ„ç”±å®ç°å†³å®šï¼›\n",
    "        vae.sample(...) åšé‡å‚æ•°åŒ–é‡‡æ ·å¾—åˆ°æ½œå‘é‡ zï¼Œå½¢çŠ¶ä¸º [B, 4, 64, 64]ã€‚\n",
    "        ç›´è§‰ï¼š512Ã—512 çš„å›¾ç‰‡è¢«å‹åˆ° 64Ã—64 çš„æ½œç©ºé—´é‡Œï¼Œé€šé“æ•°æ˜¯4ã€‚\n",
    "        \"\"\"\n",
    "        #æŠ½å–å›¾åƒç‰¹å¾å›¾\n",
    "        #[1, 3, 512, 512] -> [1, 4, 64, 64]\n",
    "        out_vae = vae.encoder(data['pixel_values'])\n",
    "        out_vae = vae.sample(out_vae)\n",
    "\n",
    "        #0.18215 = vae.config.scaling_factor\n",
    "        out_vae = out_vae * 0.18215 # å…³é”®ç»†èŠ‚ï¼šStable Diffusion ä½¿ç”¨å›ºå®šç¼©æ”¾å› å­ 0.18215ï¼Œç¡®ä¿æ½œç©ºé—´çš„æ•°å€¼èŒƒå›´ä¸è®­ç»ƒæ—¶ä¸€è‡´ã€‚\n",
    "                                    # è®­ç»ƒå’Œæ¨ç†ä¸¤è¾¹éƒ½è¦ä¿æŒè¿™ä¸ªç¼©æ”¾ä¸€è‡´ï¼Œå¦åˆ™å™ªå£°å¼ºåº¦/ä¿¡å™ªæ¯”ä¼šé”™ä½ï¼Œå¯¼è‡´è®­ç»ƒ/æ¨ç†ä¸åŒ¹é…ã€‚\n",
    "\n",
    "    \"\"\"\n",
    "    é‡‡æ ·ä¸ latent åŒå½¢çŠ¶çš„æ ‡å‡†é«˜æ–¯å™ªå£° Îµï¼š\n",
    "    å½¢çŠ¶ [B, 4, 64, 64]\n",
    "    è¿™å°±æ˜¯è®­ç»ƒçš„ç›‘ç£ä¿¡å·ï¼ˆç›®æ ‡ï¼‰ï¼Œåé¢ç”¨MSEè®©UNetå»å›å½’å®ƒã€‚\n",
    "    \"\"\"\n",
    "    #éšæœºæ•°,unetçš„è®¡ç®—ç›®æ ‡\n",
    "    noise = torch.randn_like(out_vae)\n",
    "\n",
    "    #å¾€ç‰¹å¾å›¾ä¸­æ·»åŠ å™ªå£°\n",
    "    #1000 = scheduler.num_train_timesteps\n",
    "    #1 = batch size\n",
    "    noise_step = torch.randint(0, 1000, (1, )).long().to(device)\n",
    "    \"\"\"\n",
    "    éšæœºé€‰ä¸€ä¸ªæ—¶é—´æ­¥ tï¼š\n",
    "    å€¼åŸŸ [0, 999]ï¼ˆå…±1000ä¸ªè®­ç»ƒæ­¥ï¼Œå–å†³äºscheduleré…ç½®ï¼‰\n",
    "    å½¢çŠ¶æ˜¯ [1]ï¼ˆæ‰¹é‡æ˜¯1ï¼‰ã€‚\n",
    "    å¦‚æœä»¥å B>1ï¼Œé€šå¸¸å†™æˆ torch.randint(0, 1000, (B,))ï¼Œæˆ– [1] å†å¹¿æ’­ä¹Ÿè¡Œï¼Œä½†å¾ˆå¤šå®ç°è¦æ±‚ [B]ï¼Œæ›´ç¨³å¦¥ã€‚\n",
    "    \"\"\"\n",
    "    out_vae_noise = scheduler.add_noise(out_vae, noise, noise_step)\n",
    "    \"\"\"\n",
    "    æŠŠå™ªå£°æŒ‰æ‰©æ•£å…¬å¼åŠ åˆ°latentä¸Šï¼Œå¾—åˆ° x_tï¼š\n",
    "    æ•°å­¦ï¼šx_t = sqrt(Î±Ì„_t) * x_0 + sqrt(1 - Î±Ì„_t) * Îµ\n",
    "    å…¶ä¸­ x_0 å°±æ˜¯ out_vaeï¼ˆç¼©æ”¾åçš„latentï¼‰ï¼ŒÎµ æ˜¯ä¸Šé¢é‡‡çš„å™ªå£°ï¼ŒÎ±Ì„_t æ˜¯schedulerï¼ˆDDPM/DDIMç­‰ï¼‰ç»™å®šçš„ç´¯è®¡å™ªå£°è®¡åˆ’ã€‚\n",
    "    è¾“å‡ºå½¢çŠ¶ä»æ˜¯ [B, 4, 64, 64]ã€‚\n",
    "    scheduler.add_noise å†…éƒ¨ä¼šæŸ¥åˆ° t å¯¹åº”çš„ sqrt_alpha_cumprod[t] ä¸ sqrt_one_minus_alpha_cumprod[t] å¹¶åšçº¿æ€§ç»„åˆã€‚\n",
    "    \"\"\"\n",
    "\n",
    "    #æ ¹æ®æ–‡å­—ä¿¡æ¯,æŠŠç‰¹å¾å›¾ä¸­çš„å™ªå£°è®¡ç®—å‡ºæ¥\n",
    "    out_unet = unet(out_vae=out_vae_noise,\n",
    "                    out_encoder=out_encoder,\n",
    "                    time=noise_step)\n",
    "    \"\"\"\n",
    "    æŠŠå¸¦å™ªæ½œå‘é‡ x_tã€æ–‡æœ¬æ¡ä»¶ã€æ—¶é—´æ­¥ t ä¸€èµ·å–‚å…¥UNetï¼š\n",
    "    out_vae_noise: [B, 4, 64, 64]\n",
    "    out_encoder: [B, 77, 768]ï¼ˆåšCross-Attnæ¡ä»¶ï¼‰\n",
    "    time: [B]æˆ–[1]ï¼ˆä½ çš„UNeté‡Œä¸€èˆ¬ä¼šå…ˆæŠŠtè¿‡æ—¶é—´åµŒå…¥ï¼Œå¦‚æ­£å¼¦ä½ç½®ç¼–ç +MLP â†’ 1280ç»´ç­‰ï¼‰\n",
    "    UNetè¾“å‡ºé€šå¸¸æ˜¯å¯¹å™ªå£° Îµ çš„é¢„æµ‹ï¼š\n",
    "    out_unet å½¢çŠ¶ [B, 4, 64, 64]\n",
    "    \"\"\"\n",
    "\n",
    "    #è®¡ç®—mse loss\n",
    "    #[1, 4, 64, 64],[1, 4, 64, 64]\n",
    "    return criterion(out_unet, noise)\n",
    "\n",
    "\n",
    "# get_loss({\n",
    "#     'input_ids': torch.ones(1, 77, device=device).long(),\n",
    "#     'pixel_values': torch.randn(1, 3, 512, 512, device=device)\n",
    "# })"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24ddc16a",
   "metadata": {},
   "source": [
    "ä¸€å…±è®­ç»ƒ400ä¸ªepochï¼Œæ¯å››ä¸ªæ‰¹æ¬¡æˆ‘ä»¬è¿›è¡Œä¸€æ¬¡å‚æ•°çš„è°ƒæ•´ \n",
    "\n",
    "å®ƒçš„ä½œç”¨\n",
    "torch.nn.utils.clip_grad_norm_(unet.parameters(), 1.0) =\n",
    "æŠŠ unet æ‰€æœ‰å‚æ•°çš„**æ¢¯åº¦å‘é‡çš„æ•´ä½“é•¿åº¦ï¼ˆL2 èŒƒæ•°ï¼‰**é™åˆ¶åœ¨ 1.0 ä»¥å†…ï¼Œé˜²æ­¢æ¢¯åº¦è¿‡å¤§ï¼ˆæ¢¯åº¦çˆ†ç‚¸ï¼‰ã€‚\n",
    "\n",
    "ä¸ºä»€ä¹ˆè¦è¿™ä¹ˆåš\n",
    "æ¢¯åº¦å¤ªå¤§ â†’ ä¸€æ­¥æ›´æ–°è·³å¾—è¿‡çŒ› â†’ è®­ç»ƒä¸ç¨³å®šç”šè‡³å‘æ•£ã€‚\n",
    "è£å‰ªåï¼šæ–¹å‘ä¸å˜ï¼Œé•¿åº¦å˜å°ï¼Œæ›´æ–°æ›´ç¨³ã€‚\n",
    "\n",
    "å®ƒå…·ä½“å¹²äº†ä¸‰æ­¥\n",
    "\n",
    "- æŠŠæ‰€æœ‰å‚æ•°çš„æ¢¯åº¦æ‹¼æˆä¸€ä¸ªâ€œå¤§å‘é‡â€ï¼Œç®—å®ƒçš„ L2 èŒƒæ•° total_normã€‚\n",
    "- å¦‚æœ total_norm â‰¤ 1.0ï¼šå•¥ä¹Ÿä¸åšã€‚\n",
    "-  total_norm > 1.0ï¼šæŠŠæ‰€æœ‰æ¢¯åº¦åŒæ—¶ä¹˜ä»¥ 1.0 / total_normï¼ˆç»Ÿä¸€ç¼©æ”¾ï¼‰ï¼Œè®©æ•´ä½“èŒƒæ•°æ­£å¥½å˜æˆ 1.0ã€‚\n",
    "\n",
    "è¶…ç®€ä¾‹å­\n",
    "å‡è®¾ä¸¤ä¸ªå‚æ•°çš„æ¢¯åº¦æ˜¯ g1=3ã€g2=4ï¼Œæ•´ä½“èŒƒæ•° sqrt(3^2+4^2)=5 > 1ã€‚\n",
    "ç¼©æ”¾ç³»æ•° = 1/5 = 0.2ï¼Œæ‰€ä»¥æ–°æ¢¯åº¦å˜ä¸º g1=0.6ã€g2=0.8ã€‚\n",
    "â†’ æ–¹å‘ç›¸åŒï¼ˆæ¯”ä¾‹æ²¡å˜ï¼‰ï¼Œåªæ˜¯æ•´ä½“â€œé•¿åº¦â€ä» 5 ç¼©åˆ° 1ã€‚\n",
    "\n",
    "æ”¾åœ¨ä½ è¿™æ®µä»£ç é‡Œçš„å«ä¹‰\n",
    "ä½ æ¯ç´¯è®¡ 4 æ¬¡ loss.backward() æ‰ optimizer.step()ï¼Œè¿™è¡Œå°±åœ¨ step ä¹‹å‰æŠŠç´¯è®¡åçš„æ€»æ¢¯åº¦è£å‰ªåˆ° â‰¤ 1.0ï¼Œä¿è¯è¿™æ¬¡æ›´æ–°ä¸ä¼šè¿‡çŒ›ã€‚\n",
    "\n",
    "ä¸¤ç‚¹è¡¥å……\n",
    "- è¿™æ˜¯æŒ‰èŒƒæ•°è£å‰ªï¼ˆclip_grad_norm_ï¼‰ï¼Œä¸åŒäºæŒ‰æ•°å€¼é€å…ƒç´ æˆªæ–­ï¼ˆclip_grad_value_ï¼‰ã€‚\n",
    "- å‡½æ•°ä¼šåŸåœ°ä¿®æ”¹æ¢¯åº¦ï¼Œå¹¶è¿”å›è£å‰ªå‰çš„èŒƒæ•°ï¼ˆå¯ç”¨æ¥æ‰“å°ç›‘æ§ï¼‰ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "84b88599",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 11.7118999005761\n",
      "10 105.27776907754014\n",
      "20 101.45478522218764\n",
      "30 97.96161541804031\n",
      "40 95.7652038520173\n",
      "50 92.64628775657911\n",
      "60 91.62508884524868\n",
      "70 88.90302349776903\n",
      "80 84.6358380591555\n",
      "90 82.70271758512536\n",
      "100 81.53195204613439\n",
      "110 76.3927595877758\n",
      "120 74.14106083381193\n",
      "130 71.42537906522921\n",
      "140 69.16221529991162\n",
      "150 65.47076485656726\n",
      "160 62.1360088881047\n",
      "170 60.89056803673884\n",
      "180 57.985315461344726\n",
      "190 54.73302427918679\n",
      "200 50.69724302080431\n",
      "210 48.59712202517403\n",
      "220 46.407517315681616\n",
      "230 44.99496047659704\n",
      "240 44.07751854383969\n",
      "250 39.62402399040002\n",
      "260 37.051896732489695\n",
      "270 36.89249631060375\n",
      "280 35.71413582353853\n",
      "290 33.45783720578038\n",
      "300 33.08240255239798\n",
      "310 30.282505852694158\n",
      "320 29.86848702972202\n",
      "330 29.363934024146147\n",
      "340 29.187604612583527\n",
      "350 27.543819716789585\n",
      "360 26.130621485815936\n",
      "370 25.465440133120865\n",
      "380 25.48384229660587\n",
      "390 24.789676978944044\n"
     ]
    }
   ],
   "source": [
    "def train():\n",
    "    loss_sum = 0\n",
    "    for epoch in range(400):\n",
    "        for i, data in enumerate(loader):\n",
    "            loss = get_loss(data) / 4\n",
    "            loss.backward()\n",
    "            loss_sum += loss.item()\n",
    "\n",
    "            if (epoch * len(loader) + i) % 4 == 0:\n",
    "                torch.nn.utils.clip_grad_norm_(unet.parameters(), 1.0)\n",
    "                optimizer.step()\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "        if epoch % 10 == 0:\n",
    "            print(epoch, loss_sum)\n",
    "            loss_sum = 0\n",
    "\n",
    "    #torch.save(unet.to('cpu'), 'saves/unet.model')\n",
    "\n",
    "\n",
    "train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "22f955b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a72f7737ddf24b868be27b18c5b694a2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Upload 1 LFS files:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "711d4f375af84ff59ef05920c646f3bf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "pytorch_model.bin:   0%|          | 0.00/3.44G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "CommitInfo(commit_url='https://huggingface.co/lansinuote/diffsion_from_scratch.unet/commit/32f5e4163edb6d1a3fa1d8265ad2cdf0406cb425', commit_message='Upload model', commit_description='', oid='32f5e4163edb6d1a3fa1d8265ad2cdf0406cb425', pr_url=None, pr_revision=None, pr_num=None)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import PreTrainedModel, PretrainedConfig\n",
    "\n",
    "\n",
    "#åŒ…è£…ç±»\n",
    "class Model(PreTrainedModel):\n",
    "    config_class = PretrainedConfig\n",
    "\n",
    "    def __init__(self, config):\n",
    "        super().__init__(config)\n",
    "        self.unet = unet.to('cpu')\n",
    "\n",
    "#ä¿å­˜åˆ°hub\n",
    "Model(PretrainedConfig()).push_to_hub(\n",
    "    repo_id='lansinuote/diffsion_from_scratch.unet',\n",
    "    use_auth_token=open('/root/hub_token.txt').read().strip())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
